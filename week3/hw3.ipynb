{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homework 3:\n",
    "\"\"\"\n",
    "The pipeline is created in Mage. \n",
    "\n",
    "The purpose of this jupyter notebook is just to explain each option selected. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1: Run Mage\n",
    "#0.9.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2: Creating the homework_03 project\n",
    "#metadata.yaml has 55 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3: Creating the pipeline\n",
    "#Load Stage - block to download data\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "if 'data_loader' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_loader\n",
    "\n",
    "\n",
    "@data_loader\n",
    "def load_files(**kwargs) -> pd.DataFrame:\n",
    "    #load data from the github\n",
    "    response = requests.get(\n",
    "        f'https://github.com/nevinpolat/mlops-zoomcamp/blob/main/week3/data/yellow_tripdata_2023-03.parquet?raw=true'\n",
    "            )         \n",
    "\n",
    "    if response.status_code != 200:\n",
    "                raise Exception(response.text)\n",
    "\n",
    "    df = pd.read_parquet(BytesIO(response.content))\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mage output: 3403766 rows x 19 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4: Data preparation\n",
    "#Transform Stage -block to clean data , remove outliers etc. \n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "\n",
    "@transformer\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "    # Convert pickup and dropoff datetime columns to datetime type\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "\n",
    "    # Calculate the trip duration in minutes\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Filter out trips that are less than 1 minute or more than 60 minutes\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mage output: 3316216 rows x 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5: Train a model\n",
    "#Transform stage -block to create feature matrix \n",
    "#and train the model with linear regression \n",
    "#and print the y-intercept\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "\n",
    "@transformer\n",
    "def read_dataframe(df: pd.DataFrame):\n",
    "\n",
    "    #One hot coding\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    \n",
    "    train_dicts = df[categorical].to_dict(orient='records')\n",
    "    \n",
    "    #create feature matrix \n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    \n",
    "    #Training the data  with linear regression\n",
    "\n",
    "    target = 'duration'\n",
    "    y_train = df[target].values\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_train)\n",
    "\n",
    "    print('y-Intercept is:', lr.intercept_) \n",
    "\n",
    "    return dv,lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mage output:y-Intercept is: 24.776533894980524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6: Register the model\n",
    "#Export Stage - block to register the linear regression model and \n",
    "#to save the dict vectorizer \n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "if 'data_exporter' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_exporter\n",
    "\n",
    "@data_exporter\n",
    "def register_model(df: pd.DataFrame,*args,**kwargs) -> None:\n",
    "    \n",
    "    MLFLOW_TRACKING_URI = \"sqlite:///home/mlflow/mlflow.db\"\n",
    "    mlflow.set_experiment(\"LR-model\")   \n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "\n",
    "        dv,lr = df\n",
    "        #Save and log the artifact (dict vectorizer)\n",
    "        with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "       \n",
    "        # Log the linear regression model and register as version 1\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=lr,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=\"linear-reg-model\",\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mage output:\n",
    "\"\"\"\n",
    "2024/06/04 15:28:29 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
    "\n",
    "Successfully registered model 'linear-reg-model'.\n",
    "\n",
    "Created version '1' of model 'linear-reg-model'.\n",
    "\n",
    "mlflow_version: 2.12.1\n",
    "model_size_bytes: 4534\n",
    "model_uuid: dee4d0d3e5624baebfdc5af11cfb8ff8\n",
    "run_id: 18350506568744c29479196a6946ac7d\n",
    "utc_time_created: '2024-06-04 15:28:29.762933'\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
